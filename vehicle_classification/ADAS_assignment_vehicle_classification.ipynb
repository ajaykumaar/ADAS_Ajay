{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "8LJz6s1RM_ec"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2"
      ],
      "metadata": {
        "id": "iaO6G_97fynd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ocmKYm1N3WB",
        "outputId": "8fc841a2-3902-4afd-f906-8b18a0f11452"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YDMnnJ9OBWuqL1OBF6Um\")\n",
        "project = rf.workspace(\"roboflow-gw7yv\").project(\"vehicles-openimages\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cgWFs911XQ5",
        "outputId": "74b2c74c-ae1f-47f8-9597-169b7a8c3ec7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m995.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.6/77.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Vehicles-OpenImages-1 to yolov7pytorch:: 100%|██████████| 39360/39360 [00:02<00:00, 17764.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Vehicles-OpenImages-1 in yolov7pytorch:: 100%|██████████| 2520/2520 [00:00<00:00, 2890.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git"
      ],
      "metadata": {
        "id": "tC4EOAo5v6Yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b333c677-197a-46eb-b216-fde986726862"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1197, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 1197 (delta 2), reused 3 (delta 1), pack-reused 1191\u001b[K\n",
            "Receiving objects: 100% (1197/1197), 74.24 MiB | 30.64 MiB/s, done.\n",
            "Resolving deltas: 100% (518/518), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G-0RTvOyBB5a"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r yolov7/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKiM0prwfxRN",
        "outputId": "5f6f95ed-26cf-4f09-ba09-287c50b90e92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n"
      ],
      "metadata": {
        "id": "OuEzbTZLfxNf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from models.yolo import Model\n",
        "from utils.general import check_requirements, set_logging\n",
        "from utils.google_utils import attempt_download\n",
        "from utils.torch_utils import select_device\n",
        "\n",
        "# dependencies = ['torch', 'yaml']\n",
        "# check_requirements(Path(\"/content/yolov7/requirements.txt\"), exclude=('pycocotools', 'thop'))\n",
        "set_logging()\n"
      ],
      "metadata": {
        "id": "IZpLUiZUkDuW"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb3oNPt4Lim3",
        "outputId": "62bd4452-e27c-4047-8eb4-fac197b65f3b"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best.pt\t\t\t\t   output_detections.mp4    sample_data       yolov7\n",
            "compas_video1.mp4\t\t   output_overlay_test.mp4  video1_final.mp4\n",
            "dave-kim-OBjYlqUq8Mc-unsplash.jpg  output_plot.png\t    video3_final.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom(path_or_model='path/to/model.pt', autoshape=True):\n",
        "\n",
        "    model = torch.load(path_or_model, map_location=torch.device('cpu')) if isinstance(path_or_model, str) else path_or_model  # load checkpoint\n",
        "    if isinstance(model, dict):\n",
        "        model = model['ema' if model.get('ema') else 'model']  # load model\n",
        "\n",
        "    hub_model = Model(model.yaml).to(next(model.parameters()).device)  # create\n",
        "    hub_model.load_state_dict(model.float().state_dict())  # load state_dict\n",
        "    hub_model.names = model.names  # class names\n",
        "    if autoshape:\n",
        "        hub_model = hub_model.autoshape()\n",
        "    device = select_device('0' if torch.cuda.is_available() else 'cpu')  # default to GPU if available\n",
        "    return hub_model.to(device)\n"
      ],
      "metadata": {
        "id": "dsKSFXjPfxE3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Name of the classes according to class indices.\n",
        "names= ['Truck', 'Motorcycle', 'Car', 'Bus', 'Ambulance']\n",
        "\n",
        "\n",
        "# Creating random colors for bounding box visualization.\n",
        "colors = {\n",
        "    name: [random.randint(0, 255) for _ in range(3)] for i, name in enumerate(names)\n",
        "}"
      ],
      "metadata": {
        "id": "GpmSPCY3Osv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = custom(path_or_model='/content/best.pt')  # custom example\n",
        "\n",
        "# Verify inference\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "input_img = cv2.imread('/content/dave-kim-OBjYlqUq8Mc-unsplash.jpg')\n",
        "dim = (640, 640)\n",
        "# resize image\n",
        "input_img = cv2.resize(input_img, dim, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "results = model(input_img)\n",
        "results.print()\n",
        "# results.save()\n",
        "df_prediction = results.pandas().xyxy\n",
        "df_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za56e_c2nFk1",
        "outputId": "d0081b2e-4126-4fe5-d4fc-bfd12d99c83e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding autoShape... \n",
            "image 1/1: 640x640 3 Cars\n",
            "Speed: 5.6ms pre-process, 393.8ms inference, 23.9ms NMS per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[         xmin        ymin        xmax        ymax  confidence  class name\n",
              " 0  174.165405  272.220337  440.352173  450.955261    0.933980      2  Car\n",
              " 1  352.403961  244.585968  506.885956  385.862518    0.801100      2  Car\n",
              " 2  543.683472  241.049469  639.818115  358.438141    0.572014      2  Car]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnZE2xUm3b4d"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_detections(frame, df_prediction):\n",
        "\n",
        "  for i, row in enumerate(df_prediction[0].iterrows()):\n",
        "\n",
        "    row_index, row_data = row\n",
        "    (xmin, ymin, xmax, ymax, score, cls_id, cls_name) = row_data.to_list()\n",
        "\n",
        "    if score < 0.3:\n",
        "      continue\n",
        "\n",
        "    start_point = (int(xmin), int(ymin))\n",
        "    end_point = (int(xmax), int(ymax))\n",
        "\n",
        "    cv2.rectangle(frame, start_point, end_point, color=(0,255,0), thickness=2)\n",
        "    cv2.putText(frame, str(cls_name + str(np.round(score, 2))), (start_point[0]-3, start_point[1]-3), cv2.FONT_HERSHEY_SIMPLEX, 0.75, [225, 255, 255], thickness=2,)\n",
        "\n",
        "  return frame\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# cv2_imshow(input_img)\n",
        ""
      ],
      "metadata": {
        "id": "nBOnCP_038U3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oSJyksI6l8im"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('/content/video3_final.mp4')\n",
        "detections_frames_list = []\n",
        "\n",
        "if (cap.isOpened()== False):\n",
        "  print(\"Error opening video stream or file\")\n",
        "\n",
        "while(cap.isOpened()):\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    # frames_list.append(frame)\n",
        "    dim = (640, 640)\n",
        "    input_img = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA) # resize image\n",
        "\n",
        "    results = model(input_img)\n",
        "    results.print()\n",
        "    # results.save()\n",
        "    df_prediction = results.pandas().xyxy\n",
        "    df_prediction\n",
        "\n",
        "    detections_frames_list.append(plot_detections(frame = input_img, df_prediction= df_prediction))\n",
        "\n",
        "  else:\n",
        "    break\n",
        "cap.release()\n",
        "# frames = [detections_frames_list[i] for i in range(0,len(detections_frames_list),1)]\n",
        "len(detections_frames_list)"
      ],
      "metadata": {
        "id": "aj4pUnRrmQkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import cv2 as cv\n",
        "cap = cv2.VideoCapture(\"video1_final.mp4\")\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # float `width`\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V') #codec\n",
        "out = cv2.VideoWriter('output_detections.mp4', fourcc, 20.0, (640, 640))\n",
        "counter=0\n",
        "for frame in detections_frames_list:\n",
        "    # ret, frame = cap.read()\n",
        "\n",
        "    counter+=1\n",
        "    out.write(frame)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "# Release everything if job is finished\n",
        "print(counter)\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPbMIb-xOwui",
        "outputId": "83f91481-7b4d-4d67-807e-849979745c11"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPgw6Z5sPdC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R-xTbt7VPc8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "IFvZxgd2VVCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weapons_ds=[\n",
        "\n",
        "    \"train: ../Vehicles-OpenImages-1/train/images\\n\",\n",
        "     \"val: ../Vehicles-OpenImages-1/valid/images\\n\",\n",
        "     \"test: ../Vehicles-OpenImages-1/test/images\\n\\n\",\n",
        "     \"nc: 6 #number of classes\\n\",\n",
        "    \"names: ['Truck', 'Motorcycle', 'Car', 'Bus', 'Ambulance', 'person']\\n\"\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "UGHk3V5Tfw-f"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inside /yolov7\n",
        "%cd yolov7\n",
        "with open('data/vehicles_ds.yaml', 'w') as writefile:\n",
        "  for line in weapons_ds:\n",
        "    print(line)\n",
        "    writefile.write(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWDZHpl9fw7v",
        "outputId": "c74a61b3-af1a-4184-b1b7-b5d8c2af304e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'yolov7'\n",
            "/content/yolov7\n",
            "train: ../Vehicles-OpenImages-1/train/images\n",
            "\n",
            "val: ../Vehicles-OpenImages-1/valid/images\n",
            "\n",
            "test: ../Vehicles-OpenImages-1/test/images\n",
            "\n",
            "\n",
            "nc: 6 #number of classes\n",
            "\n",
            "names: ['Truck', 'Motorcycle', 'Car', 'Bus', 'Ambulance', 'person']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#edit /content/yolov7/cfg/training/yolov7-tiny.yaml file before training"
      ],
      "metadata": {
        "id": "AwNuQiI6VY6S"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --epochs 50 --data data/vehicles_ds.yaml --img 640 640 --cfg cfg/training/yolov7-tiny.yaml --workers 4 --device 0 --batch-size 64 \\\n",
        "--weights '/content/yolov7-tiny.pt' --name yolov7tiny_vehicles_det_fixed_res --hyp data/hyp.scratch.tiny.yaml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l-9zHr3fw4C",
        "outputId": "48f1ec40-b272-460c-b0a1-a58dd406adca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 10:09:21.175833: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-07 10:09:21.175883: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-07 10:09:21.175981: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-07 10:09:22.237383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "YOLOR 🚀 v0.1-128-ga207844 torch 2.1.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='/content/yolov7-tiny.pt', cfg='cfg/training/yolov7-tiny.yaml', data='data/vehicles_ds.yaml', hyp='data/hyp.scratch.tiny.yaml', epochs=50, batch_size=64, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=4, project='runs/train', entity=None, name='yolov7tiny_vehicles_det_fixed_res', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7tiny_vehicles_det_fixed_res3', total_batch_size=64)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.05, copy_paste=0.0, paste_in=0.05, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            "  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  8                -1  1         0  models.common.MP                        []                            \n",
            "  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 15                -1  1         0  models.common.MP                        []                            \n",
            " 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 22                -1  1         0  models.common.MP                        []                            \n",
            " 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 31                -1  1         0  models.common.SP                        [5]                           \n",
            " 32                -2  1         0  models.common.SP                        [9]                           \n",
            " 33                -3  1         0  models.common.SP                        [13]                          \n",
            " 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 36          [-1, -7]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 41          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 59          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
            " 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 67          [-1, 37]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 77      [74, 75, 76]  1     30662  models.yolo.IDetect                     [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 263 layers, 6028518 parameters, 6028518 gradients, 13.2 GFLOPS\n",
            "\n",
            "Transferred 330/344 items from /content/yolov7-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 58 .bias, 58 conv.weight, 61 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../Vehicles-OpenImages-1/train/labels.cache' images and labels... 878 found, 0 missing, 0 empty, 0 corrupted: 100% 878/878 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../Vehicles-OpenImages-1/valid/labels.cache' images and labels... 250 found, 0 missing, 0 empty, 0 corrupted: 100% 250/250 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.81, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/yolov7tiny_vehicles_det_fixed_res3\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/49     2.02G   0.08342   0.03804   0.05615    0.1776       172       640: 100% 14/14 [00:55<00:00,  3.99s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:12<00:00,  6.00s/it]\n",
            "                 all         250         454     0.00714       0.113     0.00402    0.000709\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/49     10.6G   0.07263   0.01425   0.04324    0.1301       193       640: 100% 14/14 [00:24<00:00,  1.75s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.73s/it]\n",
            "                 all         250         454      0.0192       0.245      0.0128     0.00313\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/49     12.9G   0.06382   0.01532    0.0345    0.1136       153       640: 100% 14/14 [00:27<00:00,  1.97s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.86s/it]\n",
            "                 all         250         454       0.157       0.168        0.12       0.054\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/49     12.9G   0.05859   0.01512   0.03088    0.1046       190       640: 100% 14/14 [00:29<00:00,  2.10s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.82s/it]\n",
            "                 all         250         454       0.393       0.318       0.281       0.128\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/49     12.9G   0.05592   0.01437   0.02771     0.098       198       640: 100% 14/14 [00:29<00:00,  2.08s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.26s/it]\n",
            "                 all         250         454       0.351       0.412        0.33       0.167\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/49     12.9G   0.05481   0.01416   0.02452   0.09348       163       640: 100% 14/14 [00:26<00:00,  1.90s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.74s/it]\n",
            "                 all         250         454       0.428       0.396       0.365        0.16\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/49     12.9G   0.05222   0.01376   0.02527   0.09125       142       640: 100% 14/14 [00:28<00:00,  2.05s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.80s/it]\n",
            "                 all         250         454       0.414       0.457        0.39       0.192\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/49     12.9G    0.0514   0.01389   0.02298   0.08827       166       640: 100% 14/14 [00:28<00:00,  2.04s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.81s/it]\n",
            "                 all         250         454       0.501       0.423       0.451       0.236\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/49     12.9G   0.05088   0.01401   0.02136   0.08625       194       640: 100% 14/14 [00:27<00:00,  1.98s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.71s/it]\n",
            "                 all         250         454       0.394       0.584       0.451       0.217\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/49     12.9G      0.05   0.01418    0.0221   0.08629       149       640: 100% 14/14 [00:32<00:00,  2.32s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.51s/it]\n",
            "                 all         250         454       0.511       0.427       0.444       0.257\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/49     12.9G   0.04821   0.01402   0.01946   0.08169       199       640: 100% 14/14 [00:28<00:00,  2.04s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.90s/it]\n",
            "                 all         250         454       0.465       0.508       0.449       0.211\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/49     12.9G   0.04828   0.01384   0.01914   0.08127       181       640: 100% 14/14 [00:29<00:00,  2.14s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.74s/it]\n",
            "                 all         250         454       0.521       0.548       0.489       0.296\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/49     12.9G   0.04655   0.01446   0.01718   0.07819       191       640: 100% 14/14 [00:27<00:00,  1.99s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.86s/it]\n",
            "                 all         250         454       0.452       0.603        0.48       0.268\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/49     12.9G    0.0467   0.01371   0.01724   0.07766       145       640: 100% 14/14 [00:29<00:00,  2.12s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.30s/it]\n",
            "                 all         250         454       0.471       0.526       0.488       0.243\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/49     12.9G   0.04645    0.0138   0.01605   0.07629       174       640: 100% 14/14 [00:30<00:00,  2.17s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.01s/it]\n",
            "                 all         250         454       0.529       0.579        0.55        0.32\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/49     12.9G   0.04565   0.01387   0.01428    0.0738       228       640: 100% 14/14 [00:27<00:00,  1.97s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.88s/it]\n",
            "                 all         250         454       0.569       0.548       0.538       0.329\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/49     12.9G   0.04423   0.01357   0.01543   0.07322       182       640: 100% 14/14 [00:28<00:00,  2.03s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.20s/it]\n",
            "                 all         250         454       0.635       0.454        0.57       0.336\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/49     12.9G   0.04305   0.01371   0.01456   0.07132       163       640: 100% 14/14 [00:28<00:00,  2.01s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.55s/it]\n",
            "                 all         250         454       0.467       0.632        0.54       0.322\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/49     12.9G   0.04156   0.01333   0.01359   0.06848       166       640: 100% 14/14 [00:31<00:00,  2.22s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.84s/it]\n",
            "                 all         250         454       0.526       0.617       0.589        0.35\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/49     12.9G   0.04269   0.01349   0.01238   0.06855       177       640: 100% 14/14 [00:29<00:00,  2.09s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.91s/it]\n",
            "                 all         250         454       0.561       0.581       0.591       0.378\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/49     12.9G    0.0416   0.01272   0.01145   0.06577       127       640: 100% 14/14 [00:29<00:00,  2.09s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.09s/it]\n",
            "                 all         250         454       0.539       0.618       0.565       0.376\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/49     12.9G   0.04081   0.01351   0.01159    0.0659       175       640: 100% 14/14 [00:28<00:00,  2.00s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.74s/it]\n",
            "                 all         250         454       0.578       0.573       0.576        0.38\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/49     12.9G   0.03937   0.01344   0.01135   0.06416       157       640: 100% 14/14 [00:30<00:00,  2.14s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.61s/it]\n",
            "                 all         250         454       0.618        0.57       0.597       0.392\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/49     12.9G   0.03958   0.01353   0.01085   0.06396       165       640: 100% 14/14 [00:27<00:00,  2.00s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.73s/it]\n",
            "                 all         250         454       0.626        0.56       0.589       0.412\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/49     12.9G   0.03919   0.01336    0.0101   0.06266       183       640: 100% 14/14 [00:28<00:00,  2.06s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.68s/it]\n",
            "                 all         250         454       0.598       0.557       0.588       0.403\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/49     12.9G   0.03837   0.01311    0.0103   0.06178       173       640: 100% 14/14 [00:29<00:00,  2.12s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.13s/it]\n",
            "                 all         250         454       0.661       0.551         0.6       0.415\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/49     12.9G   0.03652   0.01298  0.009838   0.05934       164       640: 100% 14/14 [00:26<00:00,  1.89s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.67s/it]\n",
            "                 all         250         454       0.671       0.568       0.611       0.417\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/49     12.9G   0.03698   0.01292  0.009652   0.05955       184       640: 100% 14/14 [00:28<00:00,  2.06s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.70s/it]\n",
            "                 all         250         454       0.729       0.536        0.62       0.432\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/49     12.9G   0.03633   0.01287  0.009067   0.05827       163       640: 100% 14/14 [00:28<00:00,  2.02s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.75s/it]\n",
            "                 all         250         454       0.666       0.586       0.638       0.439\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/49     12.9G   0.03576   0.01327  0.009011   0.05804       164       640: 100% 14/14 [00:28<00:00,  2.07s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.19s/it]\n",
            "                 all         250         454       0.632       0.607       0.636       0.441\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/49     12.9G   0.03575   0.01261  0.008495   0.05685       163       640: 100% 14/14 [00:27<00:00,  1.98s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.12s/it]\n",
            "                 all         250         454       0.583       0.686       0.651       0.444\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/49     12.9G   0.03457   0.01351  0.008389   0.05647       195       640: 100% 14/14 [00:28<00:00,  2.01s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.09s/it]\n",
            "                 all         250         454       0.612       0.607       0.624        0.44\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/49     12.9G   0.03344   0.01224  0.007731   0.05341       142       640: 100% 14/14 [00:28<00:00,  2.02s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.74s/it]\n",
            "                 all         250         454       0.629       0.641       0.637       0.436\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/49     12.9G   0.03469   0.01327  0.008565   0.05652       168       640: 100% 14/14 [00:28<00:00,  2.03s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.74s/it]\n",
            "                 all         250         454       0.654       0.596       0.636       0.443\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/49     12.9G   0.03409   0.01295  0.007837   0.05487       172       640: 100% 14/14 [00:27<00:00,  1.97s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.75s/it]\n",
            "                 all         250         454       0.612       0.646       0.628       0.433\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/49     12.9G   0.03295   0.01322  0.007901   0.05408       185       640: 100% 14/14 [00:28<00:00,  2.06s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.28s/it]\n",
            "                 all         250         454       0.522       0.746       0.632       0.454\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/49     12.9G   0.03166   0.01292  0.007496   0.05208       174       640: 100% 14/14 [00:27<00:00,  1.94s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.15s/it]\n",
            "                 all         250         454       0.596       0.666       0.624       0.436\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/49     12.9G   0.03187   0.01275  0.006334   0.05095       168       640: 100% 14/14 [00:27<00:00,  1.97s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.70s/it]\n",
            "                 all         250         454       0.577        0.65       0.627        0.44\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/49     12.9G   0.03137   0.01271  0.006781   0.05086       169       640: 100% 14/14 [00:29<00:00,  2.11s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.62s/it]\n",
            "                 all         250         454       0.597       0.673       0.642       0.454\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/49     12.9G   0.03114   0.01221  0.006838   0.05019       180       640: 100% 14/14 [00:27<00:00,  1.99s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.78s/it]\n",
            "                 all         250         454       0.602       0.675       0.639        0.46\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/49     12.9G   0.03048   0.01263  0.006936   0.05004       155       640: 100% 14/14 [00:28<00:00,  2.03s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.15s/it]\n",
            "                 all         250         454       0.623       0.672        0.64       0.461\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/49     12.9G   0.03045   0.01235  0.006948   0.04976       181       640: 100% 14/14 [00:28<00:00,  2.03s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.43s/it]\n",
            "                 all         250         454       0.625       0.635       0.647       0.468\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/49     12.9G   0.03118   0.01252  0.007367   0.05107       183       640: 100% 14/14 [00:29<00:00,  2.09s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.61s/it]\n",
            "                 all         250         454       0.578       0.685       0.651       0.472\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/49     12.9G   0.03046   0.01274  0.006388   0.04959       186       640: 100% 14/14 [00:28<00:00,  2.02s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.74s/it]\n",
            "                 all         250         454       0.594       0.669       0.648       0.472\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/49     12.9G   0.02985   0.01271  0.006686   0.04925       203       640: 100% 14/14 [00:28<00:00,  2.03s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.99s/it]\n",
            "                 all         250         454       0.586       0.708       0.653       0.478\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     45/49     12.9G   0.03048   0.01293  0.006137   0.04956       195       640: 100% 14/14 [00:25<00:00,  1.84s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.51s/it]\n",
            "                 all         250         454       0.663       0.614       0.656       0.474\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/49     12.9G   0.02892   0.01185  0.005496   0.04626       157       640: 100% 14/14 [00:25<00:00,  1.85s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.33s/it]\n",
            "                 all         250         454       0.676       0.606        0.65        0.47\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/49     12.9G   0.02975    0.0127  0.006068   0.04852       172       640: 100% 14/14 [00:28<00:00,  2.00s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.63s/it]\n",
            "                 all         250         454       0.624       0.676       0.646       0.463\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/49     12.9G   0.02915   0.01257  0.006416   0.04814       142       640: 100% 14/14 [00:28<00:00,  2.07s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:03<00:00,  1.77s/it]\n",
            "                 all         250         454       0.622       0.675        0.65       0.468\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/49     12.9G   0.02949    0.0122  0.005714    0.0474       154       640: 100% 14/14 [00:28<00:00,  2.00s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:10<00:00,  5.17s/it]\n",
            "                 all         250         454       0.657       0.646        0.65        0.47\n",
            "               Truck         250          64        0.71       0.875       0.862       0.714\n",
            "          Motorcycle         250          46       0.701       0.715       0.774        0.59\n",
            "                 Car         250         238       0.611       0.597        0.58        0.37\n",
            "                 Bus         250          46       0.697       0.609       0.612       0.397\n",
            "           Ambulance         250          60       0.565       0.433        0.42       0.277\n",
            "50 epochs completed in 0.489 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/yolov7tiny_vehicles_det_fixed_res3/weights/last.pt, 12.3MB\n",
            "Optimizer stripped from runs/train/yolov7tiny_vehicles_det_fixed_res3/weights/best.pt, 12.3MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov7/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMllMg-Pfw1I",
        "outputId": "0bd7066c-8e96-4b02-83f2-adb2b2beee36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "shodSvnAOuxY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}